{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "62wDAuoM9y7D"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "olivetti = fetch_olivetti_faces()\n",
        "x = olivetti.images\n",
        "y = olivetti.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPGYP1do-a6C",
        "outputId": "f9606d9c-2d7a-4cf2-da77-2c1b8d33d82e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW2878l0AF8_",
        "outputId": "4872732f-53bf-4691-d26d-770c8b09ab33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available.  Training on CPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating CNN architecture for A model"
      ],
      "metadata": {
        "id": "y9t9oTolK0St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetA(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network=nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Conv2d(32,64,kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Conv2d(64,128,kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(51200,10))\n",
        "        \n",
        "  def forward(self, x):\n",
        "    return self.network(x)\n",
        "\n",
        "#Creating a CNN architecture\n",
        "modelA = NetA()\n",
        "print(modelA)"
      ],
      "metadata": {
        "id": "ncGeehTKI0YU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064a85f4-bd1e-4e76-b1dd-09eba22aff42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetA(\n",
            "  (network): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=51200, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a CNN Architecture for B model"
      ],
      "metadata": {
        "id": "Fergtw8QK-0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetB(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network=nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=3, stride=1),\n",
        "        nn.Conv2d(32,64,kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Conv2d(64,128,kernel_size=3, stride=1),\n",
        "        nn.Conv2d(128,256,kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(102400, 10)\n",
        "        )\n",
        "        \n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.network(x)\n",
        "\n",
        "#Creating a CNN architecture\n",
        "modelB = NetB()\n",
        "print(modelB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buf3ejC5KPUx",
        "outputId": "20420b85-311b-418e-888a-cdac39dbd945"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetB(\n",
            "  (network): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (2): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=102400, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a CNN architecture for C model"
      ],
      "metadata": {
        "id": "CSF_ST9MLHEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetC(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network=nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=1),\n",
        "        nn.MaxPool2d(3, stride=1),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(51200, 10),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(10, 25600))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.network(x)\n",
        "\n",
        "#Creating a CNN architecture\n",
        "modelC = NetC()\n",
        "print(modelC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM02U1qiKavl",
        "outputId": "d7b62c4e-1c86-4efc-b0e1-77700ba6f813"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetC(\n",
            "  (network): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=51200, out_features=10, bias=True)\n",
            "    (8): Flatten(start_dim=1, end_dim=-1)\n",
            "    (9): Linear(in_features=10, out_features=25600, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MxUXxceb9Atl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJi9Fn_1gMWb",
        "outputId": "d617280e-6525-453a-88ee-9a1d114ecdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 5s 303ms/step - loss: 3.7157 - accuracy: 0.0188 - val_loss: 3.6917 - val_accuracy: 0.0125\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.6895 - accuracy: 0.0188 - val_loss: 3.6991 - val_accuracy: 0.0125\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 3.6848 - accuracy: 0.0312 - val_loss: 3.7119 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 2s 212ms/step - loss: 3.6770 - accuracy: 0.0312 - val_loss: 3.7304 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 3.6613 - accuracy: 0.0344 - val_loss: 3.7056 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 3s 351ms/step - loss: 3.6193 - accuracy: 0.0719 - val_loss: 3.7223 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 2s 216ms/step - loss: 3.5088 - accuracy: 0.1250 - val_loss: 3.7138 - val_accuracy: 0.0500\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 2s 214ms/step - loss: 3.2842 - accuracy: 0.2031 - val_loss: 3.4752 - val_accuracy: 0.1250\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 2.8747 - accuracy: 0.3156 - val_loss: 3.1624 - val_accuracy: 0.1625\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 2.1772 - accuracy: 0.4812 - val_loss: 2.5444 - val_accuracy: 0.3625\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 3s 324ms/step - loss: 1.6067 - accuracy: 0.5875 - val_loss: 1.8489 - val_accuracy: 0.5250\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 2s 227ms/step - loss: 1.0189 - accuracy: 0.7563 - val_loss: 1.5313 - val_accuracy: 0.6375\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.7376 - accuracy: 0.8062 - val_loss: 1.2684 - val_accuracy: 0.6000\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 2s 217ms/step - loss: 0.5470 - accuracy: 0.8469 - val_loss: 0.9097 - val_accuracy: 0.7125\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.3260 - accuracy: 0.9281 - val_loss: 0.6808 - val_accuracy: 0.8125\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 3s 256ms/step - loss: 0.2120 - accuracy: 0.9594 - val_loss: 0.4961 - val_accuracy: 0.8625\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 3s 291ms/step - loss: 0.1334 - accuracy: 0.9719 - val_loss: 0.5833 - val_accuracy: 0.8375\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 2s 222ms/step - loss: 0.0741 - accuracy: 0.9969 - val_loss: 0.3023 - val_accuracy: 0.9250\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 2s 220ms/step - loss: 0.0660 - accuracy: 0.9875 - val_loss: 0.3801 - val_accuracy: 0.9000\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 2s 213ms/step - loss: 0.0458 - accuracy: 0.9969 - val_loss: 0.3779 - val_accuracy: 0.9125\n",
            "Epoch 1/10\n",
            "10/10 [==============================] - 4s 348ms/step - loss: 3.7047 - accuracy: 0.0125 - val_loss: 3.6948 - val_accuracy: 0.0500\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 3s 242ms/step - loss: 3.6874 - accuracy: 0.0406 - val_loss: 3.7080 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 2s 225ms/step - loss: 3.6842 - accuracy: 0.0437 - val_loss: 3.7220 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 2s 223ms/step - loss: 3.6748 - accuracy: 0.0344 - val_loss: 3.7325 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 2s 225ms/step - loss: 3.6558 - accuracy: 0.0312 - val_loss: 3.7229 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 3s 305ms/step - loss: 3.5893 - accuracy: 0.0688 - val_loss: 3.7324 - val_accuracy: 0.0125\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 3s 259ms/step - loss: 3.3900 - accuracy: 0.1344 - val_loss: 3.5001 - val_accuracy: 0.0750\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 2s 222ms/step - loss: 2.9616 - accuracy: 0.2062 - val_loss: 3.1431 - val_accuracy: 0.1250\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 2s 219ms/step - loss: 2.2706 - accuracy: 0.3781 - val_loss: 2.4878 - val_accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 3s 279ms/step - loss: 1.5168 - accuracy: 0.6187 - val_loss: 1.7396 - val_accuracy: 0.5000\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.7396 - accuracy: 0.5000\n",
            "Test accuracy: 0.5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "olivetti = fetch_olivetti_faces()\n",
        "X = olivetti.images\n",
        "y = olivetti.target\n",
        "\n",
        "# Preprocess the data\n",
        "X = X.reshape((X.shape[0], 64, 64, 1))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Define the model architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(64,64,1)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(40, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "\"\"\"**ARCHITECTURE B**\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(256 * 6 * 6, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Convolutional layers\n",
        "        x = self.conv1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv4(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        # Flatten and fully connected layer\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\"\"\"**ARCHITECTURE C**\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Olivetti faces dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.data.reshape(-1, 64, 64, 1)  # Reshape the input data to a 4D tensor\n",
        "y = faces.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=40, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Question A Side effects if we increase the network size"
      ],
      "metadata": {
        "id": "zAa9cR4E-_vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "# Download Olivetti faces dataset\n",
        "olivetti = fetch_olivetti_faces()\n",
        "x = olivetti.images\n",
        "y = olivetti.target\n",
        "\n",
        "# Define the neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=40):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(64 * 8 * 8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.pool3(x)\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a function to train the model and return the accuracy\n",
        "def train_and_evaluate(model, x, y):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    for epoch in range(20):\n",
        "        running_loss = 0.0\n",
        "        for i in range(0, len(x), 32):\n",
        "            inputs = torch.from_numpy(x[i:i+32]).float()\n",
        "            labels = torch.from_numpy(y[i:i+32]).long()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs.unsqueeze(1))\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print('[%d] loss: %.3f' % (epoch + 1, running_loss / len(x)))\n",
        "\n",
        "    _, predicted = torch.max(model(torch.from_numpy(x).unsqueeze(1).float()), 1)\n",
        "    accuracy = (predicted.numpy() == y).mean()\n",
        "    return accuracy\n",
        "\n",
        "# Define a list of numbers of filters for the convolutional layers\n",
        "filter_sizes = [16, 32, 64, 128, 256]\n",
        "\n",
        "# Train and evaluate the models with different filter sizes\n",
        "accuracies = []\n",
        "for size in filter_sizes:\n",
        "    model = Net(num_classes=40)\n",
        "    accuracy = train_and_evaluate(model, x, y)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Plot the accuracy vs. filter size\n",
        "plt.plot(filter_sizes, accuracies, '-o')\n",
        "plt.xlabel('Filter Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n_DMurLpC15Y",
        "outputId": "cb27dd9c-f43c-477a-9b4c-c7b5e0ce5fe8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 0.123\n",
            "[2] loss: 0.120\n",
            "[3] loss: 0.120\n",
            "[4] loss: 0.120\n",
            "[5] loss: 0.120\n",
            "[6] loss: 0.120\n",
            "[7] loss: 0.120\n",
            "[8] loss: 0.120\n",
            "[9] loss: 0.120\n",
            "[10] loss: 0.120\n",
            "[11] loss: 0.120\n",
            "[12] loss: 0.120\n",
            "[13] loss: 0.120\n",
            "[14] loss: 0.120\n",
            "[15] loss: 0.120\n",
            "[16] loss: 0.120\n",
            "[17] loss: 0.120\n",
            "[18] loss: 0.120\n",
            "[19] loss: 0.120\n",
            "[20] loss: 0.120\n",
            "[1] loss: 0.124\n",
            "[2] loss: 0.120\n",
            "[3] loss: 0.120\n",
            "[4] loss: 0.120\n",
            "[5] loss: 0.120\n",
            "[6] loss: 0.120\n",
            "[7] loss: 0.120\n",
            "[8] loss: 0.120\n",
            "[9] loss: 0.120\n",
            "[10] loss: 0.120\n",
            "[11] loss: 0.120\n",
            "[12] loss: 0.120\n",
            "[13] loss: 0.120\n",
            "[14] loss: 0.119\n",
            "[15] loss: 0.116\n",
            "[16] loss: 0.112\n",
            "[17] loss: 0.104\n",
            "[18] loss: 0.090\n",
            "[19] loss: 0.078\n",
            "[20] loss: 0.063\n",
            "[1] loss: 0.124\n",
            "[2] loss: 0.120\n",
            "[3] loss: 0.120\n",
            "[4] loss: 0.120\n",
            "[5] loss: 0.120\n",
            "[6] loss: 0.120\n",
            "[7] loss: 0.120\n",
            "[8] loss: 0.120\n",
            "[9] loss: 0.120\n",
            "[10] loss: 0.120\n",
            "[11] loss: 0.119\n",
            "[12] loss: 0.121\n",
            "[13] loss: 0.119\n",
            "[14] loss: 0.118\n",
            "[15] loss: 0.117\n",
            "[16] loss: 0.115\n",
            "[17] loss: 0.113\n",
            "[18] loss: 0.114\n",
            "[19] loss: 0.111\n",
            "[20] loss: 0.104\n",
            "[1] loss: 0.123\n",
            "[2] loss: 0.120\n",
            "[3] loss: 0.120\n",
            "[4] loss: 0.120\n",
            "[5] loss: 0.120\n",
            "[6] loss: 0.120\n",
            "[7] loss: 0.120\n",
            "[8] loss: 0.120\n",
            "[9] loss: 0.117\n",
            "[10] loss: 0.120\n",
            "[11] loss: 0.113\n",
            "[12] loss: 0.110\n",
            "[13] loss: 0.097\n",
            "[14] loss: 0.078\n",
            "[15] loss: 0.057\n",
            "[16] loss: 0.036\n",
            "[17] loss: 0.039\n",
            "[18] loss: 0.067\n",
            "[19] loss: 0.063\n",
            "[20] loss: 0.025\n",
            "[1] loss: 0.124\n",
            "[2] loss: 0.120\n",
            "[3] loss: 0.120\n",
            "[4] loss: 0.120\n",
            "[5] loss: 0.120\n",
            "[6] loss: 0.120\n",
            "[7] loss: 0.120\n",
            "[8] loss: 0.120\n",
            "[9] loss: 0.120\n",
            "[10] loss: 0.124\n",
            "[11] loss: 0.120\n",
            "[12] loss: 0.122\n",
            "[13] loss: 0.122\n",
            "[14] loss: 0.120\n",
            "[15] loss: 0.119\n",
            "[16] loss: 0.119\n",
            "[17] loss: 0.118\n",
            "[18] loss: 0.114\n",
            "[19] loss: 0.115\n",
            "[20] loss: 0.108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question B"
      ],
      "metadata": {
        "id": "73TNmoir-SWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load Olivetti Faces dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.data.reshape(-1, 64, 64, 1)  # Reshape to (n_samples, height, width, channels)\n",
        "y = faces.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))  # Experiment with different pooling sizes here\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(40, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model on testing data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NLwsoO1PyQo",
        "outputId": "a696edaa-f997-4679-f3cf-90913060a239"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 5s 423ms/step - loss: 3.7118 - accuracy: 0.0156 - val_loss: 3.6983 - val_accuracy: 0.0250\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 2s 244ms/step - loss: 3.6857 - accuracy: 0.0250 - val_loss: 3.6923 - val_accuracy: 0.0250\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 2s 234ms/step - loss: 3.6779 - accuracy: 0.0750 - val_loss: 3.6999 - val_accuracy: 0.0375\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 2s 156ms/step - loss: 3.6768 - accuracy: 0.0656 - val_loss: 3.7128 - val_accuracy: 0.0125\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 3.6512 - accuracy: 0.0875 - val_loss: 3.7066 - val_accuracy: 0.0375\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 2s 163ms/step - loss: 3.6279 - accuracy: 0.0844 - val_loss: 3.7036 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 3.5662 - accuracy: 0.1156 - val_loss: 3.6699 - val_accuracy: 0.0750\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 3.4558 - accuracy: 0.2844 - val_loss: 3.5871 - val_accuracy: 0.1625\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 2s 164ms/step - loss: 3.2519 - accuracy: 0.2906 - val_loss: 3.4396 - val_accuracy: 0.1750\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 3s 288ms/step - loss: 2.9583 - accuracy: 0.3438 - val_loss: 3.1470 - val_accuracy: 0.2625\n",
            "Test accuracy: 0.2625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Load Olivetti Faces dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.data.reshape(-1, 64, 64, 1)  # Reshape to (n_samples, height, width, channels)\n",
        "y = faces.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(10,10)))  # Experiment with different pooling sizes here\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(40, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate model on testing data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {test_acc:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887c7f21-4693-440d-8ab4-73af5fb9babd",
        "id": "PdjgnHfdR6vW"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 4s 294ms/step - loss: 3.7027 - accuracy: 0.0312 - val_loss: 3.6980 - val_accuracy: 0.0250\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 2s 166ms/step - loss: 3.6842 - accuracy: 0.0375 - val_loss: 3.7027 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 3s 277ms/step - loss: 3.6808 - accuracy: 0.0312 - val_loss: 3.7107 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 2s 157ms/step - loss: 3.6738 - accuracy: 0.0312 - val_loss: 3.7197 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 3.6666 - accuracy: 0.0312 - val_loss: 3.7299 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 2s 155ms/step - loss: 3.6564 - accuracy: 0.0469 - val_loss: 3.7312 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 3.6447 - accuracy: 0.0437 - val_loss: 3.7539 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 3.6251 - accuracy: 0.0469 - val_loss: 3.7527 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 2s 154ms/step - loss: 3.6042 - accuracy: 0.0562 - val_loss: 3.7274 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 2s 251ms/step - loss: 3.5747 - accuracy: 0.0688 - val_loss: 3.7503 - val_accuracy: 0.0250\n",
            "Test accuracy: 0.0250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So we can observe that as the pool size increases test accuracy score decreases"
      ],
      "metadata": {
        "id": "_WKUSHp3_vWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question C"
      ],
      "metadata": {
        "id": "H0poYO8j_WnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.data\n",
        "y = faces.target\n",
        "\n",
        "# Preprocess data\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=X.shape[1]),\n",
        "    Dense(40, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kQcIYSfNuGc",
        "outputId": "869b11a0-70a5-47c6-b5b3-2a1fa3f89a10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 4.1147 - accuracy: 0.0375 - val_loss: 3.7040 - val_accuracy: 0.0375\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 23ms/step - loss: 3.5908 - accuracy: 0.0375 - val_loss: 3.6146 - val_accuracy: 0.0750\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.5031 - accuracy: 0.0656 - val_loss: 3.6179 - val_accuracy: 0.0500\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.4601 - accuracy: 0.0406 - val_loss: 3.5412 - val_accuracy: 0.0875\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.3867 - accuracy: 0.1219 - val_loss: 3.4806 - val_accuracy: 0.1000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 24ms/step - loss: 3.2991 - accuracy: 0.1219 - val_loss: 3.5251 - val_accuracy: 0.0375\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 3.2370 - accuracy: 0.1531 - val_loss: 3.4211 - val_accuracy: 0.1000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 21ms/step - loss: 3.1723 - accuracy: 0.1844 - val_loss: 3.3290 - val_accuracy: 0.1000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3.0494 - accuracy: 0.2469 - val_loss: 3.3612 - val_accuracy: 0.1375\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 2.9457 - accuracy: 0.2781 - val_loss: 3.2217 - val_accuracy: 0.1625\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.8682 - accuracy: 0.3156 - val_loss: 3.2850 - val_accuracy: 0.1500\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.7693 - accuracy: 0.3281 - val_loss: 3.0926 - val_accuracy: 0.1500\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 2.6513 - accuracy: 0.3531 - val_loss: 3.0374 - val_accuracy: 0.2125\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 2.5642 - accuracy: 0.4000 - val_loss: 2.8845 - val_accuracy: 0.2250\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 2.4278 - accuracy: 0.4062 - val_loss: 2.8468 - val_accuracy: 0.2500\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 2.3357 - accuracy: 0.4812 - val_loss: 2.9771 - val_accuracy: 0.2000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 2.2347 - accuracy: 0.4563 - val_loss: 2.6573 - val_accuracy: 0.3000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 2.1351 - accuracy: 0.5063 - val_loss: 2.6131 - val_accuracy: 0.2750\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 2.0439 - accuracy: 0.5500 - val_loss: 2.4907 - val_accuracy: 0.3375\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 1.9442 - accuracy: 0.5562 - val_loss: 2.4239 - val_accuracy: 0.4875\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 1.8572 - accuracy: 0.5969 - val_loss: 2.2754 - val_accuracy: 0.4125\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1.7277 - accuracy: 0.6719 - val_loss: 2.1413 - val_accuracy: 0.5375\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 1.6441 - accuracy: 0.6812 - val_loss: 2.1542 - val_accuracy: 0.5500\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.5528 - accuracy: 0.6875 - val_loss: 2.0627 - val_accuracy: 0.4500\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 1.5013 - accuracy: 0.7156 - val_loss: 1.9076 - val_accuracy: 0.6250\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.3913 - accuracy: 0.7344 - val_loss: 1.9189 - val_accuracy: 0.5125\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 1.3482 - accuracy: 0.7375 - val_loss: 1.8179 - val_accuracy: 0.5625\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.2948 - accuracy: 0.7656 - val_loss: 1.7590 - val_accuracy: 0.5750\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.2172 - accuracy: 0.7812 - val_loss: 1.7152 - val_accuracy: 0.6500\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1608 - accuracy: 0.8031 - val_loss: 1.6779 - val_accuracy: 0.5750\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 1.1267 - accuracy: 0.8219 - val_loss: 1.5412 - val_accuracy: 0.6875\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.0597 - accuracy: 0.7969 - val_loss: 1.5284 - val_accuracy: 0.6750\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 1.0315 - accuracy: 0.8062 - val_loss: 1.5654 - val_accuracy: 0.6250\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.9809 - accuracy: 0.8344 - val_loss: 1.4746 - val_accuracy: 0.6625\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.9300 - accuracy: 0.8313 - val_loss: 1.4082 - val_accuracy: 0.7125\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.9021 - accuracy: 0.8438 - val_loss: 1.3600 - val_accuracy: 0.6875\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8458 - accuracy: 0.8687 - val_loss: 1.3021 - val_accuracy: 0.7000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.8065 - accuracy: 0.8719 - val_loss: 1.3536 - val_accuracy: 0.6875\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7830 - accuracy: 0.8656 - val_loss: 1.2846 - val_accuracy: 0.7000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.7391 - accuracy: 0.8875 - val_loss: 1.2365 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.7157 - accuracy: 0.8656 - val_loss: 1.1633 - val_accuracy: 0.7375\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.8875 - val_loss: 1.2009 - val_accuracy: 0.7125\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.6700 - accuracy: 0.8844 - val_loss: 1.1118 - val_accuracy: 0.7125\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6305 - accuracy: 0.8938 - val_loss: 1.1139 - val_accuracy: 0.7375\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.6035 - accuracy: 0.9062 - val_loss: 1.0830 - val_accuracy: 0.7375\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.6051 - accuracy: 0.8969 - val_loss: 1.0883 - val_accuracy: 0.7625\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5654 - accuracy: 0.9125 - val_loss: 1.0345 - val_accuracy: 0.7625\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.5510 - accuracy: 0.9156 - val_loss: 1.0093 - val_accuracy: 0.7375\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 0.5291 - accuracy: 0.9219 - val_loss: 1.0437 - val_accuracy: 0.7750\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.5029 - accuracy: 0.9281 - val_loss: 0.9418 - val_accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f14c08bd670>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this implementation, we've experimented with different pooling sizes by changing the second MaxPooling2D layer from (2, 2) to (4, 4) larger pooling sizes can lead to more information loss and may result in lower accuracy, while smaller pooling sizes may lead to overfitting."
      ],
      "metadata": {
        "id": "lQ1t7yEb_pPl"
      }
    }
  ]
}